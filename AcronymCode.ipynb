{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "## Before execution please note that filepath, a test string should be copied to the driver code in the end of this code\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#first, we will read the file.\n",
    "#######PLEASE NOTE THAT YOU HAVE TO COPY THE SAME FILE PATH IN THE DRIVER CODE MENTIONED IN THE LAST PART OF THE CODE BEFORE EXECUTING THE PROGRAM#######\n",
    "def read_file(filename='acronym_example1.txt'): #The same file or filepath needs to be mentioned in the s= read_file() in DRIVER CODE IN THE LAST LINES OF THE CODE. You can easily find the driver code below by reaching the last few lines of the code\n",
    "    f = open(filename, \"r\", encoding=\"utf8\")\n",
    "    s = f.read()\n",
    "    return s\n",
    "\n",
    "## QUESTION 1. PART 1 DEFINING THE FUNCTION TO FIND THE ACRONYMS\n",
    "## BEFORE executing, PLEASE NOTE that if you are testing the code by pasting a string or opening a file,\n",
    "#  the same string should be copied to the acronyms = find_acronyms(s) in DRIVER CODE below\n",
    "\n",
    "def find_acronyms(s):\n",
    " \n",
    "    acronyms_nf=[]\n",
    "    #Using the regex function and defining a pattern for the identification.\n",
    "    acronyms_nf=re.findall(r'(?:[A-Z]{2,}[:alpha:]|[a-z][A-Z]{2,}|\\([A-Z]{2,}\\)|[A-Z]{2,}[-A-Z]*)',s)\n",
    "    acronyms_nf=list(dict.fromkeys(acronyms_nf))\n",
    "    acronyms=[]\n",
    "    for acronym in acronyms_nf:\n",
    "       \n",
    "     acronym = acronym.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "     if  acronym not in acronyms:\n",
    "         acronyms.append(acronym )\n",
    "    return acronyms\n",
    "### QUESTION 1 . PART 2 FINDING THE LONG FORMS\n",
    "\n",
    "## Initially we find the stopwords and remove them\n",
    "def remove_mystopwords(sentence):\n",
    "    tokens = str(sentence).split(\" \") ##Splitting the sentence and words ##\n",
    "    tokens_filtered= [word for word in tokens if not word in list(set(stopwords.words(\"english\")))] ##We have applied a filter \n",
    "    return (\" \".join(tokens_filtered))\n",
    "\n",
    "def find_long_forms(s, acronyms):\n",
    "    sentences= s.split('.')\n",
    "    d={}\n",
    "    acronym_sentence ={}\n",
    "    # cycle through sentences and index which sentence the acronym appears for the first time\n",
    "    for acronym in acronyms:\n",
    "        for sent in sentences:\n",
    "            if acronym in sent and acronym not in acronym_sentence.keys():\n",
    "                sent = sent.replace(\"'s\",\" \").replace(\"(\", \"\").replace(\")\", \"\").replace(\"-\", \" \").replace(\"'\", \" \")\n",
    "                acronym_sentence[acronym]= sent\n",
    "    # Searching the acronyms in the sentences and returning the associated long forms           \n",
    "    for acronym in acronym_sentence:\n",
    "        sentence = acronym_sentence.get(acronym)\n",
    "        new_filtered_sentence = remove_mystopwords(sentence) #Preparing a new filtered sentence\n",
    "        full_form = find_org(new_filtered_sentence, acronym)\n",
    "        d[acronym] = full_form  \n",
    "    \n",
    "    return d\n",
    "##QUESTION 1 PART 3 REPLACING THE ACRONYM WITH THE FULL FORM.\n",
    "# In some cases, full form and acronym might be together but the sentence has been regenerated by replacing the acronym in quotation mark or comma, with the full form and associated acronym.\n",
    "def replace_acronyms(s, d):\n",
    "    #doc = nlp(s)\n",
    "    new_s = \" \"\n",
    "    for sent in s.split(\".\"):\n",
    "    #rule 1 check for dictionary keys, if short form and long form both are present then don't replace\n",
    "        if words_in_string(d.keys(), sent) and not words_in_string(d.values(),sent):\n",
    "            for word in words_in_string(d.keys(), sent):\n",
    "                if d[word] and word:\n",
    "                    new_s = new_s + sent.replace(word, d[word])\n",
    "                else:\n",
    "                    new_s = new_s + sent\n",
    "        else:\n",
    "            new_s = new_s + sent\n",
    "    # rule 2 if only short form is there in stenence find it and replace with first letter capital\n",
    "    return new_s\n",
    "\n",
    "\n",
    "\n",
    "def find_org(text, acronym):\n",
    "    # good for abbrevs that are in all caps.\n",
    "    try:\n",
    "        text = text.split(acronym)[0]\n",
    "    except:\n",
    "        text = text\n",
    "    orig_text_token_list = str(text).split(\" \")\n",
    "    text_token_list = [x.title() for x in orig_text_token_list]\n",
    "    stop_w = [x.title() for x in list(set(stopwords.words(\"english\")))]\n",
    "   \n",
    "    potential_match = []\n",
    "    #if acronym is surrounded by parens, remove\n",
    "    acronym = acronym.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    # return all indices of words that start w first letter of acronym\n",
    "   \n",
    "    # remove 's and\n",
    "    for potential_start_idx in [\n",
    "        i for i, x in enumerate(text_token_list) if x[:1] == acronym[:1]\n",
    "    ]:\n",
    "        potential_match.append(text_token_list[potential_start_idx])\n",
    "        idx = potential_start_idx + 1\n",
    "        matches = \"\"\n",
    "        for i, letter in enumerate(acronym[1:]):\n",
    "            has_match = False\n",
    "            stop_word_counter = 0\n",
    "           \n",
    "            if text_token_list[idx][:1] == letter:\n",
    "                potential_match.append(orig_text_token_list[idx])\n",
    "                matches = matches + letter\n",
    "                idx = idx + 1\n",
    "                has_match = True\n",
    "               \n",
    "            while stop_word_counter <= 2 and text_token_list[idx] in stop_w:\n",
    "                potential_match.append(orig_text_token_list[idx])\n",
    "                stop_word_counter = stop_word_counter + 1\n",
    "                idx = idx + 1\n",
    "\n",
    "            if text_token_list[idx][:1] == letter and has_match == False:\n",
    "                potential_match.append(orig_text_token_list[idx])\n",
    "                matches = matches + letter\n",
    "                idx = idx + 1\n",
    "                has_match = True\n",
    "\n",
    "        if matches != acronym[1:]:\n",
    "            potential_match = []\n",
    "        if matches == acronym[1:]:\n",
    "            break\n",
    "    try:\n",
    "        if potential_match[-1].title() in stop_w:\n",
    "            potential_match = potential_match[:-1]\n",
    "        result = \" \".join(potential_match)\n",
    "    except:\n",
    "        result = None\n",
    "    return result\n",
    "\n",
    "def words_in_string(word_list, a_string):\n",
    "    return set(word_list).intersection(a_string.split())\n",
    "\n",
    "#Driver Code\n",
    "s = read_file(\"acronym_example1.txt\")\n",
    "acronyms = find_acronyms(s)\n",
    "d = find_long_forms(s, acronyms)\n",
    "new_s = replace_acronyms(s, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MRI', 'fMRI', 'BOLD', 'DMN', 'RSN', 'EEG', 'NIRS']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_acronyms(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MRI': None,\n",
       " 'fMRI': None,\n",
       " 'BOLD': 'Blood oxygen level dependent',\n",
       " 'DMN': 'Default mode network',\n",
       " 'RSN': 'Resting State Network',\n",
       " 'EEG': None,\n",
       " 'NIRS': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_long_forms(s, acronyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
